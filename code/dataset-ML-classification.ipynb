{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b812f1b-fec2-46d1-90a9-02be80c8c0d1",
   "metadata": {},
   "source": [
    "# Dataset ML Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c6cfe3-9fd7-4c7c-af92-d24a04df3440",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26a626c2-fd26-4a79-99e6-5a8b811aef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import signal\n",
    "import openml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import issparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b09561ed-7ce1-4c9f-9c42-489b39204f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_types = [\n",
    "    \"Supervised Classification\",\n",
    "    \"Supervised Regression\",\n",
    "    \"Clustering\",\n",
    "    \"Learning Curve\",\n",
    "    \"Supervised Data Stream Classification\",\n",
    "    \"Subgroup Discovery\",\n",
    "    \"Survival Analysis\"\n",
    "]\n",
    "def initialize_binary_matrix(dataset_ids, task_types):\n",
    "    binary_matrix = pd.DataFrame(0, index=dataset_ids, columns=task_types)\n",
    "    return binary_matrix\n",
    "\n",
    "def populate_binary_matrix(binary_matrix, dataset_id):\n",
    "    try:\n",
    "        # Find all tasks associated with this dataset\n",
    "        tasks = openml.tasks.list_tasks(output_format='dataframe', data_id=dataset_id)\n",
    "        \n",
    "        # Calculate the percentage each task type represents\n",
    "        task_type_counts = tasks['task_type'].value_counts(normalize=True) * 100\n",
    "        \n",
    "        # Filter task types that make up at least 20% of the total tasks\n",
    "        filtered_task_types = task_type_counts[task_type_counts >= 20]\n",
    "        \n",
    "        # If no task type meets the 20% threshold, select the top one\n",
    "        if filtered_task_types.empty:\n",
    "            filtered_task_types = task_type_counts.head(1)\n",
    "        \n",
    "        # Mark the filtered task types as 1 in the binary matrix\n",
    "        for task_type in filtered_task_types.index:\n",
    "            if task_type in binary_matrix.columns:\n",
    "                binary_matrix.at[dataset_id, task_type] = 1\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process dataset {dataset_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa749837-d85c-4ef2-8fd5-644c24d17a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22116447/timing-attack-dataset-10-micro-seconds-delay-2022-09-13.arff.\n",
      "/tmp/ipykernel_6560/436230525.py:15: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22116448/timing-attack-dataset-10-micro-seconds-delay-2022-09-14.arff.\n",
      "/tmp/ipykernel_6560/436230525.py:15: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22116449/timing-attack-dataset-10-micro-seconds-delay-2022-09-15.arff.\n",
      "/tmp/ipykernel_6560/436230525.py:15: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22116450/timing-attack-dataset-10-micro-seconds-delay-2022-09-18.arff.\n",
      "/tmp/ipykernel_6560/436230525.py:15: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22116451/timing-attack-dataset-10-micro-seconds-delay-2022-09-19.arff.\n",
      "/tmp/ipykernel_6560/436230525.py:15: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22116452/timing-attack-dataset-10-micro-seconds-delay-2022-09-20.arff.\n",
      "/tmp/ipykernel_6560/436230525.py:15: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22116453/timing-attack-dataset-10-micro-seconds-delay-2022-09-21.arff.\n",
      "/tmp/ipykernel_6560/436230525.py:15: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22116454/timing-attack-dataset-15-micro-seconds-delay-2022-09-04.arff.\n",
      "/tmp/ipykernel_6560/436230525.py:15: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22116455/timing-attack-dataset-15-micro-seconds-delay-2022-09-08.arff.\n",
      "/tmp/ipykernel_6560/436230525.py:15: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22116456/timing-attack-dataset-15-micro-seconds-delay-2022-09-09.arff.\n",
      "/tmp/ipykernel_6560/436230525.py:15: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22116457/timing-attack-dataset-15-micro-seconds-delay-2022-09-13.arff.\n",
      "/tmp/ipykernel_6560/436230525.py:15: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22116458/timing-attack-dataset-15-micro-seconds-delay-2022-09-14.arff.\n",
      "/tmp/ipykernel_6560/436230525.py:15: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22116459/timing-attack-dataset-15-micro-seconds-delay-2022-09-15.arff.\n",
      "/tmp/ipykernel_6560/436230525.py:15: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22116460/timing-attack-dataset-15-micro-seconds-delay-2022-09-18.arff.\n",
      "/tmp/ipykernel_6560/436230525.py:15: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22116461/timing-attack-dataset-15-micro-seconds-delay-2022-09-19.arff.\n",
      "/tmp/ipykernel_6560/436230525.py:15: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22116462/timing-attack-dataset-15-micro-seconds-delay-2022-09-20.arff.\n",
      "/tmp/ipykernel_6560/436230525.py:15: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22116463/timing-attack-dataset-15-micro-seconds-delay-2022-09-21.arff.\n",
      "/tmp/ipykernel_6560/436230525.py:15: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22116464/timing-attack-dataset-20-micro-seconds-delay-2022-09-04.arff.\n",
      "/tmp/ipykernel_6560/436230525.py:15: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22116465/timing-attack-dataset-20-micro-seconds-delay-2022-09-08.arff.\n",
      "/tmp/ipykernel_6560/436230525.py:15: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22116466/timing-attack-dataset-20-micro-seconds-delay-2022-09-09.arff.\n",
      "/tmp/ipykernel_6560/436230525.py:15: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-features extraction complete. Saved to 'openml_meta_features.csv'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class TimeoutException(Exception):\n",
    "    pass\n",
    "\n",
    "def timeout_handler(signum, frame):\n",
    "    raise TimeoutException\n",
    "\n",
    "# Register the timeout handler function\n",
    "signal.signal(signal.SIGALRM, timeout_handler)\n",
    "\n",
    "def convert_to_dense(X):\n",
    "    \"\"\"Convert any sparse columns in DataFrame X to dense format.\"\"\"\n",
    "    if issparse(X):\n",
    "        X = pd.DataFrame.sparse.from_spmatrix(X)\n",
    "    for col in X.columns:\n",
    "        if pd.api.types.is_sparse(X[col]):\n",
    "            X[col] = X[col].sparse.to_dense()\n",
    "    return X\n",
    "\n",
    "def extract_meta_features_with_tasks(dataset_ids, timeout=60):\n",
    "    meta_features = []\n",
    "    binary_matrix = initialize_binary_matrix(dataset_ids, task_types)\n",
    "    \n",
    "    for dataset_id in dataset_ids:\n",
    "        try:\n",
    "            # Start the timer\n",
    "            signal.alarm(timeout)\n",
    "            \n",
    "            dataset = openml.datasets.get_dataset(\n",
    "                dataset_id, \n",
    "                download_data=False,  # Do not download the actual data\n",
    "                download_qualities=True,  # Download dataset qualities\n",
    "                download_features_meta_data=True  # Download feature metadata\n",
    "            )\n",
    "            X, y, _, _ = dataset.get_data(target=dataset.default_target_attribute)\n",
    "\n",
    "            # Convert any sparse data to dense format if necessary\n",
    "            X = convert_to_dense(X)\n",
    "            \n",
    "            # Filter out non-numeric columns\n",
    "            numeric_X = X.select_dtypes(include=[np.number])\n",
    "            \n",
    "            num_instances = X.shape[0]\n",
    "            num_features = X.shape[1]\n",
    "            num_missing_values = X.isnull().sum().sum()\n",
    "            target_type = 'categorical' if y.dtype.name == 'category' else 'continuous'\n",
    "            num_classes = len(y.unique()) if target_type == 'categorical' else None\n",
    "\n",
    "            # Calculate class balance only if no class has zero instances\n",
    "            if target_type == 'categorical' and y.value_counts().min() > 0:\n",
    "                class_balance = y.value_counts().max() / y.value_counts().min()\n",
    "            else:\n",
    "                class_balance = None\n",
    "            \n",
    "            # Statistical Features on numeric data only\n",
    "            mean_features = numeric_X.mean().mean() if not numeric_X.empty else None\n",
    "            std_features = numeric_X.std(ddof=0).mean() if not numeric_X.empty else None\n",
    "            min_features = numeric_X.min().mean() if not numeric_X.empty else None\n",
    "            max_features = numeric_X.max().mean() if not numeric_X.empty else None\n",
    "            skewness_features = numeric_X.skew().mean() if not numeric_X.empty else None\n",
    "            kurtosis_features = numeric_X.kurtosis().mean() if not numeric_X.empty else None\n",
    "            \n",
    "            # Correlation Features\n",
    "            if numeric_X.shape[1] > 1:\n",
    "                correlation_matrix = numeric_X.corr().abs()\n",
    "                np.fill_diagonal(correlation_matrix.values, np.nan)\n",
    "                mean_correlation = correlation_matrix.mean().mean()\n",
    "                max_correlation = correlation_matrix.max().max()\n",
    "            else:\n",
    "                mean_correlation, max_correlation = None, None\n",
    "\n",
    "            # Data Sparsity\n",
    "            sparsity = (numeric_X == 0).sum().sum() / (num_instances * numeric_X.shape[1]) if not numeric_X.empty else None\n",
    "            \n",
    "            # Add meta-features to list\n",
    "            meta_features.append({\n",
    "                'dataset_id': dataset_id,\n",
    "                'num_instances': num_instances,\n",
    "                'num_features': num_features,\n",
    "                'num_missing_values': num_missing_values,\n",
    "                'target_type': target_type,\n",
    "                'num_classes': num_classes,\n",
    "                'class_balance': class_balance,\n",
    "                'mean_features': mean_features,\n",
    "                'std_features': std_features,\n",
    "                'min_features': min_features,\n",
    "                'max_features': max_features,\n",
    "                'skewness_features': skewness_features,\n",
    "                'kurtosis_features': kurtosis_features,\n",
    "                'mean_correlation': mean_correlation,\n",
    "                'max_correlation': max_correlation,\n",
    "                'sparsity': sparsity\n",
    "            })\n",
    "            \n",
    "            populate_binary_matrix(binary_matrix, dataset_id)\n",
    "        \n",
    "        except TimeoutException:\n",
    "            print(f\"Skipped dataset {dataset_id} due to timeout.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process dataset {dataset_id}: {e}\")\n",
    "        finally:\n",
    "            # Disable the alarm\n",
    "            signal.alarm(0)\n",
    "    \n",
    "    meta_features_df = pd.DataFrame(meta_features)\n",
    "    combined_df = meta_features_df.set_index('dataset_id').join(binary_matrix, on='dataset_id')\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "datasets = openml.datasets.list_datasets(output_format='dataframe')\n",
    "datasets = datasets[datasets['NumberOfInstances'] < 50000]\n",
    "dataset_ids = datasets['did'].tolist()[4500:4520]\n",
    "\n",
    "combined_df = extract_meta_features_with_tasks(dataset_ids)\n",
    "\n",
    "combined_df.to_csv(\"../data/openml_meta_features.csv\", index=True, mode='a', header=False)\n",
    "\n",
    "print(\"Meta-features extraction complete. Saved to 'openml_meta_features.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb5ce20-cc8b-4366-83ef-3b6287b22351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522c9c23-38ed-4359-bf9b-b362361caa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "the"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
