{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b812f1b-fec2-46d1-90a9-02be80c8c0d1",
   "metadata": {},
   "source": [
    "# Dataset ML Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c6cfe3-9fd7-4c7c-af92-d24a04df3440",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26a626c2-fd26-4a79-99e6-5a8b811aef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import issparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b09561ed-7ce1-4c9f-9c42-489b39204f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_types = [\n",
    "    \"Supervised Classification\",\n",
    "    \"Supervised Regression\",\n",
    "    \"Clustering\",\n",
    "    \"Learning Curve\",\n",
    "    \"Supervised Data Stream Classification\",\n",
    "    \"Subgroup Discovery\",\n",
    "    \"Survival Analysis\"\n",
    "]\n",
    "def initialize_binary_matrix(dataset_ids, task_types):\n",
    "    binary_matrix = pd.DataFrame(0, index=dataset_ids, columns=task_types)\n",
    "    return binary_matrix\n",
    "\n",
    "def populate_binary_matrix(binary_matrix, dataset_id):\n",
    "    try:\n",
    "        # Find all tasks associated with this dataset\n",
    "        tasks = openml.tasks.list_tasks(output_format='dataframe', data_id=dataset_id)\n",
    "        \n",
    "        # Calculate the percentage each task type represents\n",
    "        task_type_counts = tasks['task_type'].value_counts(normalize=True) * 100\n",
    "        \n",
    "        # Filter task types that make up at least 20% of the total tasks\n",
    "        filtered_task_types = task_type_counts[task_type_counts >= 20]\n",
    "        \n",
    "        # If no task type meets the 20% threshold, select the top one\n",
    "        if filtered_task_types.empty:\n",
    "            filtered_task_types = task_type_counts.head(1)\n",
    "        \n",
    "        # Mark the filtered task types as 1 in the binary matrix\n",
    "        for task_type in filtered_task_types.index:\n",
    "            if task_type in binary_matrix.columns:\n",
    "                binary_matrix.at[dataset_id, task_type] = 1\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process dataset {dataset_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa749837-d85c-4ef2-8fd5-644c24d17a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12023/637793099.py:6: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "/tmp/ipykernel_12023/637793099.py:6: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "/home/workbench/.local/lib/python3.10/site-packages/openml/datasets/dataset.py:433: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  pd.factorize(type_)[0]\n",
      "/tmp/ipykernel_12023/637793099.py:6: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "/home/workbench/.local/lib/python3.10/site-packages/openml/datasets/dataset.py:433: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  pd.factorize(type_)[0]\n",
      "/tmp/ipykernel_12023/637793099.py:6: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "/home/workbench/.local/lib/python3.10/site-packages/openml/datasets/dataset.py:433: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  pd.factorize(type_)[0]\n",
      "/tmp/ipykernel_12023/637793099.py:6: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "/home/workbench/.local/lib/python3.10/site-packages/openml/datasets/dataset.py:433: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  pd.factorize(type_)[0]\n",
      "/tmp/ipykernel_12023/637793099.py:6: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "/tmp/ipykernel_12023/637793099.py:6: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "/tmp/ipykernel_12023/637793099.py:6: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "/tmp/ipykernel_12023/637793099.py:6: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "/tmp/ipykernel_12023/637793099.py:6: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "/tmp/ipykernel_12023/637793099.py:6: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "/tmp/ipykernel_12023/637793099.py:6: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "/tmp/ipykernel_12023/637793099.py:6: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "/tmp/ipykernel_12023/637793099.py:6: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "/tmp/ipykernel_12023/637793099.py:6: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "/tmp/ipykernel_12023/637793099.py:6: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "/tmp/ipykernel_12023/637793099.py:6: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "/home/workbench/.local/lib/python3.10/site-packages/openml/datasets/dataset.py:433: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  pd.factorize(type_)[0]\n",
      "/tmp/ipykernel_12023/637793099.py:6: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "/home/workbench/.local/lib/python3.10/site-packages/openml/datasets/dataset.py:433: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  pd.factorize(type_)[0]\n",
      "/tmp/ipykernel_12023/637793099.py:6: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n",
      "/home/workbench/.local/lib/python3.10/site-packages/openml/datasets/dataset.py:433: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  pd.factorize(type_)[0]\n",
      "/tmp/ipykernel_12023/637793099.py:6: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if pd.api.types.is_sparse(X[col]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-features extraction complete. Saved to 'openml_meta_features.csv'.\n"
     ]
    }
   ],
   "source": [
    "def convert_to_dense(X):\n",
    "    \"\"\"Convert any sparse columns in DataFrame X to dense format.\"\"\"\n",
    "    if issparse(X):\n",
    "        X = pd.DataFrame.sparse.from_spmatrix(X)\n",
    "    for col in X.columns:\n",
    "        if pd.api.types.is_sparse(X[col]):\n",
    "            X[col] = X[col].sparse.to_dense()\n",
    "    return X\n",
    "    \n",
    "def extract_meta_features_with_tasks(dataset_ids):\n",
    "    meta_features = []\n",
    "    binary_matrix = initialize_binary_matrix(dataset_ids, task_types)\n",
    "    \n",
    "    for dataset_id in dataset_ids:\n",
    "        try:\n",
    "            dataset = openml.datasets.get_dataset(\n",
    "                dataset_id, \n",
    "                download_data=False,  # Do not download the actual data\n",
    "                download_qualities=True,  # Download dataset qualities\n",
    "                download_features_meta_data=True  # Download feature metadata\n",
    "            )\n",
    "            X, y, _, _ = dataset.get_data(target=dataset.default_target_attribute)\n",
    "\n",
    "            # Convert any sparse data to dense format if necessary\n",
    "            X = convert_to_dense(X)\n",
    "            \n",
    "            # Filter out non-numeric columns\n",
    "            numeric_X = X.select_dtypes(include=[np.number])\n",
    "            \n",
    "            num_instances = X.shape[0]\n",
    "            num_features = X.shape[1]\n",
    "            num_missing_values = X.isnull().sum().sum()\n",
    "            target_type = 'categorical' if y.dtype.name == 'category' else 'continuous'\n",
    "            num_classes = len(y.unique()) if target_type == 'categorical' else None\n",
    "\n",
    "            # Calculate class balance only if no class has zero instances\n",
    "            if target_type == 'categorical' and y.value_counts().min() > 0:\n",
    "                class_balance = y.value_counts().max() / y.value_counts().min()\n",
    "            else:\n",
    "                class_balance = None\n",
    "            \n",
    "            # Statistical Features on numeric data only\n",
    "            mean_features = numeric_X.mean().mean() if not numeric_X.empty else None\n",
    "            std_features = numeric_X.std(ddof=0).mean() if not numeric_X.empty else None\n",
    "            min_features = numeric_X.min().mean() if not numeric_X.empty else None\n",
    "            max_features = numeric_X.max().mean() if not numeric_X.empty else None\n",
    "            skewness_features = numeric_X.skew().mean() if not numeric_X.empty else None\n",
    "            kurtosis_features = numeric_X.kurtosis().mean() if not numeric_X.empty else None\n",
    "            \n",
    "            # Correlation Features\n",
    "            if numeric_X.shape[1] > 1:\n",
    "                correlation_matrix = numeric_X.corr().abs()\n",
    "                np.fill_diagonal(correlation_matrix.values, np.nan)\n",
    "                mean_correlation = correlation_matrix.mean().mean()\n",
    "                max_correlation = correlation_matrix.max().max()\n",
    "            else:\n",
    "                mean_correlation, max_correlation = None, None\n",
    "\n",
    "            # Data Sparsity\n",
    "            sparsity = (numeric_X == 0).sum().sum() / (num_instances * numeric_X.shape[1]) if not numeric_X.empty else None\n",
    "            \n",
    "            # Add meta-features to list\n",
    "            meta_features.append({\n",
    "                'dataset_id': dataset_id,\n",
    "                'num_instances': num_instances,\n",
    "                'num_features': num_features,\n",
    "                'num_missing_values': num_missing_values,\n",
    "                'target_type': target_type,\n",
    "                'num_classes': num_classes,\n",
    "                'class_balance': class_balance,\n",
    "                'mean_features': mean_features,\n",
    "                'std_features': std_features,\n",
    "                'min_features': min_features,\n",
    "                'max_features': max_features,\n",
    "                'skewness_features': skewness_features,\n",
    "                'kurtosis_features': kurtosis_features,\n",
    "                'mean_correlation': mean_correlation,\n",
    "                'max_correlation': max_correlation,\n",
    "                'sparsity': sparsity\n",
    "            })\n",
    "            \n",
    "            populate_binary_matrix(binary_matrix, dataset_id)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process dataset {dataset_id}: {e}\")\n",
    "    \n",
    "    meta_features_df = pd.DataFrame(meta_features)\n",
    "    combined_df = meta_features_df.set_index('dataset_id').join(binary_matrix, on='dataset_id')\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "\n",
    "datasets = openml.datasets.list_datasets(output_format='dataframe')\n",
    "dataset_ids = datasets['did'].tolist()[230:250]\n",
    "\n",
    "combined_df = extract_meta_features_with_tasks(dataset_ids)\n",
    "\n",
    "combined_df.to_csv(\"../data/openml_meta_features.csv\", index=True, mode='a', header=False)\n",
    "\n",
    "print(\"Meta-features extraction complete. Saved to 'openml_meta_features.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6a17976-f416-4335-9c71-b1dd19fc3fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5741"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = openml.datasets.list_datasets(output_format='dataframe')\n",
    "\n",
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658ea2a8-afcf-426b-a144-e99c35a380f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
